road_network_encoder_config:
  road_id_emb_dim: 64
  len_emb_dim: 16
  type_emb_dim: 16
  lon_emb_dim: 16
  lat_emb_dim: 16
  intersection_emb_dim: 128
  zone_id_emb_dim: 128
  # determined at runtime
  road_id_num_embeddings:
  # determined at runtime
  type_num_embeddings:
  zone_id_num_embeddings: 300

# determined at runtime
road_network_encoder_feature:
  road_attr:
    len:
    type:
    lon:
    lat:
  road_edge_index:
  intersection_attr:
  zone_edge_index:
  zone_edge_weight:

trajectory_encoder_config:
  hidden_dim: 128
  num_heads: 2
  num_layers: 2
  dropout: 0.0
  max_len: 1024
  grad_checkpoint: false # Disabled: we have enough VRAM, this trades memory for speed

navigator_config:
  hidden_dim: 128

optimizer_config:
  max_epoch: 25
  batch_size: 128  # Reduced from 512, which was inefficient for the GPU architecture
  accum_steps: 1   # No accumulation needed with large batch
  learning_rate: 0.001
  weight_decay: 0.1
  warmup_ratio: 0.1
  max_norm: 1.0

# Distillation settings (used by train_with_distill.py)
distill:
  enable: true
  repo: /home/matt/Dev/LMTAD
  ckpt: /home/matt/Dev/LMTAD/code/results/LMTAD/beijing_hoser_reference/run_20250928_202718/outlier_False/n_layer_8_n_head_12_n_embd_768_lr_0.0003_integer_poe_False/weights_only.pt
  window: 32  # Much more aggressive - 4x original size
  lambda: 0.01
  temperature: 2.0
  grid_size: 0.001  # Based on LM-TAD training: grip_size="205 252" (no downsampling)
  downsample: 1     # No downsampling for this model

# Point to the original HOSER dataset (beijing_hoser_reference is LM-TAD format only)
data_dir: /home/matt/Dev/HOSER-dataset

# Dataloader performance knobs - optimized for small dataset
dataloader:
  num_workers: 4   # Reduced from 16 - small dataset doesn't need many workers
  pin_memory: true # Enable for faster GPU transfer
  prefetch_factor: 4  # Increased for better pipelining
  persistent_workers: true

# Data-specific knobs
data:
  candidate_top_k: 32  # Even more aggressive - 8x original size

# Training performance knobs
training:
  allow_tf32: true
  cudnn_benchmark: true
  torch_compile: true
  disable_cudagraphs: true

# Weights & Biases logging
wandb:
  enable: true
  project: hoser-distill
  run_name: ''
  tags: [beijing, lmtad, distillation]
